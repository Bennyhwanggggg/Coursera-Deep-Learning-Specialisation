{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13 Quiz - Special applications: Face recognition & Neural style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Face verification requires comparing a new picture against one person’s face, whereas face recognition requires comparing a new picture against K person’s faces.\n",
    "\n",
    "- [ ] True\n",
    "- [ ] False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why do we learn a function $d(img1,img2)$ for face verification? (Select all that apply.)\n",
    "\n",
    "- [ ] Given how few images we have per person, we need to apply transfer learning.\n",
    "- [ ] This allows us to learn to recognize a new person given just a single image of that person.\n",
    "- [ ] This allows us to learn to predict a person’s identity using a softmax output unit, where the number of classes equals the number of persons in the database plus 1 (for the final “not in database” class).\n",
    "- [ ] We need to solve a one-shot learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. In order to train the parameters of a face recognition system, it would be reasonable to use a training set comprising 100,000 pictures of 100,000 different persons.\n",
    "\n",
    "- [ ] True\n",
    "- [ ] False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Which of the following is a correct definition of the triplet loss? Consider that $α>0$. (We encourage you to figure out the answer from first principles, rather than just refer to the lecture.)\n",
    "\n",
    "- [ ] $max(||f(A)−f(P)||^{2}−||f(A)−f(N)||^{2}−α,0)$\n",
    "- [ ] $max(||f(A)−f(P)||^{2}−||f(A)−f(N)||^{2}+α,0)$\n",
    "- [ ] $max(||f(A)−f(N)||^{2}−||f(A)−f(P)||^{2}−α,0)$\n",
    "- [ ] $max(||f(A)−f(N)||^{2}−||f(A)−f(P)||^{2}+α,0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Consider the following Siamese network architecture:\n",
    "\n",
    "<img src=\"images/xryVS70VEee3NhLzohKsog_98c778df87f041af9903bd66d2d98bbd_Screen-Shot-2017-10-29-at-6.57.51-PM.png\"  alt=\"Figure 1\" style=\"width: 50%;\">\n",
    "\n",
    "The upper and lower neural networks have different input images, but have exactly the same parameters.\n",
    "\n",
    "- [ ] True\n",
    "- [ ] False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. You train a ConvNet on a dataset with 100 different classes. You wonder if you can find a hidden unit which responds strongly to pictures of cats. (I.e., a neuron so that, of all the input/training images that strongly activate that neuron, the majority are cat pictures.) You are more likely to find this unit in layer 4 of the network than in layer 1.\n",
    "\n",
    "- [ ] True\n",
    "- [ ] False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Neural style transfer is trained as a supervised learning task in which the goal is to input two images ($x$), and train a network to output a new, synthesized image ($y$).\n",
    "\n",
    "- [ ] True\n",
    "- [ ] False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. In the deeper layers of a ConvNet, each channel corresponds to a different feature detector. The style matrix $G^{[l]}$ measures the degree to which the activations of different feature detectors in layer l vary (or correlate) together with each other.\n",
    "\n",
    "- [ ] True\n",
    "- [ ] False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. In neural style transfer, what is updated in each iteration of the optimization algorithm?\n",
    "\n",
    "- [ ] The pixel values of the generated image $G$\n",
    "- [ ] The regularization parameters\n",
    "- [ ] The pixel values of the content image $C$\n",
    "- [ ] The neural network parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. You are working with 3D data. You are building a network layer whose input volume has size 32x32x32x16 (this volume has 16 channels), and applies convolutions with 32 filters of dimension 3x3x3 (no padding, stride 1). What is the resulting output volume?\n",
    "\n",
    "- [ ] 30x30x30x16\n",
    "- [ ] Undefined: This convolution step is impossible and cannot be performed because the dimensions specified don’t match up.\n",
    "- [ ] 30x30x30x32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
